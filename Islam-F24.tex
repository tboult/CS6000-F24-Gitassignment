\section{Goals for the Course}

As a PhD candidate in Security under the guidance of Dr Sang-Yoon Chang, my primary goal in the "Computer Science Research - CS 6000" course is to deepen my understanding of advanced research methodologies and refine my ability to conduct impactful research in security. This course represents a pivotal opportunity to explore the latest trends, challenges, and innovations in cybersecurity, allowing me to develop a comprehensive framework for addressing complex issues in this domain. Through rigorous analysis and the application of various research techniques, I aim to contribute novel insights to the academic community while also developing practical solutions that can be applied in real-world scenarios.\\

In particular, I am eager to enhance my skills in identifying, analyzing, and solving complex security problems, focusing on areas such as adversarial attacks, secure system design, and the development of robust defence mechanisms. By the end of this course, I hope to have a well-rounded understanding of how to conduct high-quality research that not only advances theoretical knowledge but also has tangible impacts on the security landscape. My ultimate goal is to leverage this knowledge to produce a dissertation that is both academically rigorous and practically significant, contributing to the field of cybersecurity in meaningful ways.\\

Personally, I am married and the father of two energetic boys, both seven years old. Balancing family life with academic pursuits is both challenging and rewarding, and I find that travelling with my family during free time and vacations provides the perfect opportunity to relax and gain new perspectives. My journey from Bangladesh to my current PhD program represents not just a professional ambition but also a personal commitment to growth and learning.

\begin{figure}[h!]
\centering
\includegraphics[width=0.5\textwidth]{images/Amanul_Islam.jpg}
\caption{Amanul Islam}
\label{fig:myphoto}
\end{figure}


\section*{Output of the Training and Validation Loss of Anomaly-Detection-in-Fake-Base-Station-using-Autoencoder: }

I tested the (https://github.com/Luckyaman/Anomaly-Detection-in-Fake-Base-Station-using-Autoencoder.git) related to anomaly detection in 5G networks.

For this project, I tested an autoencoder-based anomaly detection model for 5G networks using a GitHub repository. Over the course of 50 epochs, the model's training and validation losses converged, though fluctuating near similar values. The training process was time-intensive, with some epochs taking over two minutes each. Despite stable loss values, the model ultimately detected 717 anomalies from the dataset. The experience highlighted the need for careful tuning of hyperparameters and further exploration of feature engineering to improve the model’s performance. It was a valuable learning experience in anomaly detection within telecommunications networks.

Epoch 1/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 120s 2ms/step - loss: 0.7488 - val_loss: 0.7521
Epoch 2/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 115s 2ms/step - loss: 0.7974 - val_loss: 0.7516
Epoch 3/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 122s 2ms/step - loss: 0.6965 - val_loss: 0.7520
Epoch 4/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 124s 2ms/step - loss: 0.8732 - val_loss: 0.7520
Epoch 5/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 129s 2ms/step - loss: 0.7421 - val_loss: 0.7518
Epoch 6/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 128s 2ms/step - loss: 0.9766 - val_loss: 0.7513
Epoch 7/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 136s 2ms/step - loss: 0.7514 - val_loss: 0.7513
Epoch 8/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 125s 2ms/step - loss: 0.9412 - val_loss: 0.7512
Epoch 9/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 126s 2ms/step - loss: 0.7056 - val_loss: 0.7512
Epoch 10/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 145s 2ms/step - loss: 0.8189 - val_loss: 0.7518
Epoch 11/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 134s 2ms/step - loss: 0.8691 - val_loss: 0.7512
Epoch 12/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 121s 2ms/step - loss: 0.7325 - val_loss: 0.7512
Epoch 13/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 120s 2ms/step - loss: 0.7405 - val_loss: 0.7519
Epoch 14/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 124s 2ms/step - loss: 0.8846 - val_loss: 0.7517
Epoch 15/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 166s 2ms/step - loss: 0.8146 - val_loss: 0.7517
Epoch 16/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 191s 2ms/step - loss: 0.8228 - val_loss: 0.7512
Epoch 17/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 148s 2ms/step - loss: 0.8338 - val_loss: 0.7512
Epoch 18/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 219s 3ms/step - loss: 0.9288 - val_loss: 0.7512
Epoch 19/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 182s 2ms/step - loss: 0.8441 - val_loss: 0.7512
Epoch 20/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 127s 2ms/step - loss: 0.8198 - val_loss: 0.7512
Epoch 21/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 126s 2ms/step - loss: 0.7595 - val_loss: 0.7516
Epoch 22/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 139s 2ms/step - loss: 0.9608 - val_loss: 0.7518
Epoch 23/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 122s 2ms/step - loss: 0.8043 - val_loss: 0.7512
Epoch 24/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 144s 2ms/step - loss: 0.8094 - val_loss: 0.7523
Epoch 25/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 143s 2ms/step - loss: 0.8531 - val_loss: 0.7512
Epoch 26/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 121s 2ms/step - loss: 0.7947 - val_loss: 0.7511
Epoch 27/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 123s 2ms/step - loss: 0.7315 - val_loss: 0.7512
Epoch 28/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 122s 2ms/step - loss: 0.8460 - val_loss: 0.7512
Epoch 29/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 116s 2ms/step - loss: 0.7275 - val_loss: 0.7517
Epoch 30/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 137s 2ms/step - loss: 0.8481 - val_loss: 0.7512
Epoch 31/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 144s 2ms/step - loss: 0.8883 - val_loss: 0.7512
Epoch 32/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 111s 2ms/step - loss: 0.9098 - val_loss: 0.7512
Epoch 33/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 111s 2ms/step - loss: 0.8350 - val_loss: 0.7512
Epoch 34/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 145s 2ms/step - loss: 0.7062 - val_loss: 0.7512
Epoch 35/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 139s 2ms/step - loss: 0.8112 - val_loss: 0.7511
Epoch 36/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 152s 2ms/step - loss: 1.0590 - val_loss: 0.7513
Epoch 37/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 123s 2ms/step - loss: 0.7585 - val_loss: 0.7512
Epoch 38/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 139s 2ms/step - loss: 0.7457 - val_loss: 0.7517
Epoch 39/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 136s 2ms/step - loss: 0.7591 - val_loss: 0.7517
Epoch 40/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 134s 2ms/step - loss: 0.7131 - val_loss: 0.7512
Epoch 41/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 143s 2ms/step - loss: 0.8032 - val_loss: 0.7511
Epoch 42/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 133s 2ms/step - loss: 0.7928 - val_loss: 0.7512
Epoch 43/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 150s 2ms/step - loss: 0.8165 - val_loss: 0.7512
Epoch 44/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 136s 2ms/step - loss: 1.1533 - val_loss: 0.7517
Epoch 45/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 148s 2ms/step - loss: 0.7264 - val_loss: 0.7512
Epoch 46/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 141s 2ms/step - loss: 0.8815 - val_loss: 0.7511
Epoch 47/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 146s 2ms/step - loss: 0.7979 - val_loss: 0.7514
Epoch 48/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 211s 3ms/step - loss: 0.8380 - val_loss: 0.7511
Epoch 49/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 152s 3ms/step - loss: 0.7694 - val_loss: 0.7511
Epoch 50/50
59902/59902 ━━━━━━━━━━━━━━━━━━━━ 200s 3ms/step - loss: 0.7637 - val_loss: 0.7511
74877/74877 ━━━━━━━━━━━━━━━━━━━━ 130s 2ms/step
Number of anomalies detected: 717

\section*{Questions: }
